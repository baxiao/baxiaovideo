import streamlit as st
import os
import requests
import json
import re
import time
from openai import OpenAI
from google import genai
from google.genai import types

# --- 1. é…ç½®è¯»å– (ä» Streamlit Secrets åŠ è½½) ---
try:
    DEEPSEEK_KEY = st.secrets["DEEPSEEK_API_KEY"]
    GOOGLE_KEY = st.secrets["GOOGLE_API_KEY"]
except Exception as e:
    st.error("âŒ æœªåœ¨ Secrets ä¸­æ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
    st.stop()

# åˆå§‹åŒ– API å®¢æˆ·ç«¯
ds_client = OpenAI(api_key=DEEPSEEK_KEY, base_url="https://api.deepseek.com")
google_client = genai.Client(api_key=GOOGLE_KEY)

st.set_page_config(page_title="AIè§†é¢‘å…¨é“¾è·¯å·¥å‚", layout="wide")
st.title("ğŸ¬ çœŸå®å…¨è‡ªåŠ¨è§†é¢‘å·¥å‚")
st.caption("é›†æˆ DeepSeek æ–‡æ¡ˆã€Nano Banana ç»˜å›¾ã€Veo è§†é¢‘ç”Ÿæˆ")

# --- 2. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def get_ai_script(topic):
    """è°ƒç”¨ DeepSeek ç”Ÿæˆå¹¶æ¸…æ´— JSON è„šæœ¬"""
    prompt = f"""
    è¯·ä¸ºä¸»é¢˜â€œ{topic}â€åˆ›ä½œçŸ­è§†é¢‘è„šæœ¬ã€‚
    å¿…é¡»ä¸¥æ ¼è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼Œä¸è¦ä»»ä½•å¼€åœºç™½ã€‚
    æ•°ç»„å†…æ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
    "text": (çŸ­è§†é¢‘æ—ç™½æ–‡æ¡ˆ),
    "visual": (è¯¦ç»†çš„ç”»é¢æè¿°ï¼Œè‹±æ–‡ä¸ºä¸»),
    "camera": (è¿é•œæŒ‡ä»¤ï¼Œå¦‚: Pan left, Zoom in, Cinematic motion)
    """
    response = ds_client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}]
    )
    raw_content = response.choices[0].message.content
    
    # ã€æ ¸å¿ƒä¿®å¤ã€‘ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON æ•°ç»„éƒ¨åˆ†ï¼Œé˜²æ­¢ Expecting value æŠ¥é”™
    try:
        match = re.search(r'\[.*\]', raw_content, re.DOTALL)
        if match:
            clean_json = match.group(0)
        else:
            clean_json = raw_content.strip()
        return json.loads(clean_json)
    except Exception as e:
        st.error(f"è§£æè„šæœ¬å¤±è´¥ã€‚AIè¿”å›å†…å®¹ï¼š{raw_content}")
        return None

def generate_image_real(visual_desc):
    """è°ƒç”¨ Nano Banana (Imagen 3) ç”Ÿæˆå›¾ç‰‡æµ"""
    response = google_client.models.generate_images(
        model='imagen-3.0-generate-001',
        prompt=visual_desc,
        config=types.GenerateImagesConfig(
            number_of_images=1,
            aspect_ratio="16:9",
            output_mime_type="image/jpeg"
        )
    )
    return response.generated_images[0].image_bytes

def generate_video_real(image_bytes, camera_movement):
    """è°ƒç”¨ Veo ç”Ÿæˆè§†é¢‘æµ"""
    # ç»“åˆå›¾ç‰‡å’Œè¿é•œæŒ‡ä»¤å‘é€ç»™è§†é¢‘æ¨¡å‹
    response = google_client.models.generate_content(
        model='veo-2.0', 
        contents=[
            types.Part.from_bytes(data=image_bytes, mime_type="image/jpeg"),
            f"Generate a cinematic video based on this image with movement: {camera_movement}"
        ]
    )
    return response.candidates[0].content.parts[0].inline_data.data

# --- 3. é¡µé¢äº¤äº’ ---

user_topic = st.text_input("è¯·è¾“å…¥è§†é¢‘ä¸»é¢˜ï¼ˆå¦‚ï¼šèµ›åšæœ‹å…‹é£çš„æˆéƒ½è¡—å¤´ï¼‰ï¼š")

if st.button("ğŸš€ å¼€å¯å…¨è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿"):
    if not user_topic:
        st.warning("è¯·å…ˆè¾“å…¥ä¸»é¢˜å†…å®¹")
    else:
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆè„šæœ¬
        with st.spinner("1/3 DeepSeek æ­£åœ¨ç­–åˆ’è„šæœ¬..."):
            scenes = get_ai_script(user_topic)
        
        if scenes:
            st.success(f"âœ… è„šæœ¬ç­–åˆ’å®Œæˆï¼Œå…±è®¡ {len(scenes)} ä¸ªåˆ†é•œ")
            
            # ç¬¬äºŒæ­¥ï¼šæ ¹æ®è„šæœ¬æ•°é‡å¾ªç¯å¤„ç†
            for i, scene in enumerate(scenes):
                st.markdown(f"---")
                st.subheader(f"åˆ†é•œ #{i+1}")
                
                col_txt, col_img, col_vid = st.columns([1, 2, 2])
                
                with col_txt:
                    st.markdown("**ğŸ“œ æ—ç™½æ–‡æ¡ˆ**")
                    st.info(scene['text'])
                    st.write(f"ğŸ¥ **è¿é•œ:** {scene['camera']}")
                    # æ–¹ä¾¿æ–‡å“¥å¤åˆ¶
                    st.text_area(f"å¤åˆ¶æ–‡æ¡ˆ {i+1}", value=scene['text'], height=80, key=f"txt_{i}")

                # å®šä¹‰å›¾ç‰‡å˜é‡ä¾›è§†é¢‘ç”Ÿæˆä½¿ç”¨
                current_img_bytes = None

                with col_img:
                    with st.spinner("2/3 Nano Banana ç»˜å›¾ä¸­..."):
                        try:
                            current_img_bytes = generate_image_real(scene['visual'])
                            st.image(current_img_bytes, caption="ç”Ÿæˆçš„åˆ†é•œæ¯å›¾")
                            st.download_button("ğŸ“¥ ä¸‹è½½å›¾ç‰‡", current_img_bytes, f"img_{i+1}.jpg", "image/jpeg", key=f"dl_img_{i}")
                        except Exception as e:
                            st.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")

                with col_vid:
                    if current_img_bytes:
                        with st.spinner("3/3 Veo æ­£åœ¨åˆæˆè¿é•œè§†é¢‘..."):
                            try:
                                video_bytes = generate_video_real(current_img_bytes, scene['camera'])
                                st.video(video_bytes)
                                st.download_button("ğŸ“¥ ä¸‹è½½è§†é¢‘", video_bytes, f"vid_{i+1}.mp4", "video/mp4", key=f"dl_vid_{i}")
                            except Exception as e:
                                st.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
                                st.info("æç¤ºï¼šè¯·æ£€æŸ¥ Google è´¦å·æ˜¯å¦å·²è·å¾— Veo 2.0 æ¨¡å‹çš„ä½¿ç”¨æƒé™ã€‚")
            
            st.balloons()
